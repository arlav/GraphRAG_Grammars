{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8cd654",
   "metadata": {},
   "source": [
    "# Generative AI + GraphRAG Demo\n",
    "## House/Apartment Adjacency (Kùzu-based, No-Geometry, Global-Candidate Builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c12b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to run this cell if you have pip installed topologicpy\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/sarwj/OneDrive - Cardiff University/Documents/GitHub/topologicpy/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5176a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TopologicPy imports ---\n",
    "from topologicpy.Vertex import Vertex\n",
    "from topologicpy.Topology import Topology\n",
    "from topologicpy.Dictionary import Dictionary\n",
    "from topologicpy.Kuzu import Kuzu\n",
    "from topologicpy.Graph import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GraphRAG Demo — House/Apartment Adjacency (Kùzu-based, No-Geometry, Global-Candidate Builder)\n",
    "=====================================================================================\n",
    "\n",
    "**What this is**\n",
    "A compact, Jupyter-friendly demo that:\n",
    "1) Reads *TopologicPy-like* graphs (JSON) from a folder.\n",
    "2) Builds *topological* graphs strictly from the file's **vertices** and **edges** (ignores geometry entirely).\n",
    "3) Loads them into a Kùzu DB using your `Kuzu.py` schema (Graph, Vertex, Edge).\n",
    "4) **New logic:** At each iteration, we:\n",
    "   - Build a **global candidate list** of neighbor labels by querying *all graphs* for the labels present in the **currently built graph** (frequency-ranked).\n",
    "   - Ask the LLM to pick **one** action: either\n",
    "     - **ADD** a node (may choose from the list or propose a new label not in the list) and connect it to a chosen existing node, or\n",
    "     - **CONNECT** two existing nodes (no new node).\n",
    "   - Apply the action to the **working graph** (we create/update it in the DB).\n",
    "   - Save a full-graph snapshot and repeat until a stopping rule is met.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- We *ignore* any polygon/geometry in JSON and rely solely on `vertices` and `edges`.\n",
    "- Vertices get `label` from `node_name` or `roomtype` if present; fallback to vertex id.\n",
    "- `x,y,z` default to 0.0 if missing. Original vertex/edge dicts preserved in `props` JSON.\n",
    "- If `ANTHROPIC_API_KEY` is not set or Anthropic SDK is unavailable, a deterministic heuristic is used so the demo still runs.\n",
    "- Edge suggestions, when accepted, are inserted with label `\"suggested\"` (bidirectional for simplicity).\n",
    "- **Requested enhancement:** the seed node now **copies props (and x,y,z if present)** from the best-matching example across all graphs.\n",
    "\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "import os, json, glob\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "# --- Kùzu manager (ensure Kuzu.py is on sys.path or in the same directory) ---\n",
    "from topologicpy.Kuzu import Kuzu\n",
    "\n",
    "# --- Optional Claude/Anthropic (used only if available + key set) ---\n",
    "try:\n",
    "    from anthropic import Anthropic\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    anthropic_available = True\n",
    "except Exception:\n",
    "    anthropic_available = False\n",
    "\n",
    "# --- Optional TopologicPy for snapshots -> real Graph objects ---\n",
    "try:\n",
    "    from topologicpy.Graph import Graph as TPGraph\n",
    "    from topologicpy.Vertex import Vertex as TPVertex\n",
    "    from topologicpy.Edge import Edge as TPEdge\n",
    "    from topologicpy.Dictionary import Dictionary as TPDict\n",
    "    from topologicpy.Topology import Topology as TPTopology\n",
    "    _TOPOLOGICPY_AVAILABLE = True\n",
    "except Exception:\n",
    "    _TOPOLOGICPY_AVAILABLE = False\n",
    "\n",
    "# ---------------------\n",
    "# Data models\n",
    "# ---------------------\n",
    "@dataclass\n",
    "class Vtx:\n",
    "    id: str\n",
    "    label: str\n",
    "    x: float\n",
    "    y: float\n",
    "    z: float\n",
    "    props: Dict[str, Any]\n",
    "\n",
    "@dataclass\n",
    "class ERel:\n",
    "    src: str\n",
    "    dst: str\n",
    "    label: str\n",
    "    props: Dict[str, Any]\n",
    "\n",
    "# ---------------------\n",
    "# JSON → (Vertices, Edges)\n",
    "# ---------------------\n",
    "\n",
    "def load_topologic_graph(path: str) -> tuple[list[Vtx], list[ERel]]:\n",
    "    \"\"\"Load a TopologicPy-like graph JSON. We ignore geometry; we only use vertices and edges dictionaries.\n",
    "    Expected (flexible) shape:\n",
    "    {\n",
    "      \"vertices\": {\n",
    "          \"Vertex_0000\": {\"node_name\": \"Entrance\", \"x\": 1.2, \"y\": 3.4, ...},\n",
    "          ...\n",
    "      },\n",
    "      \"edges\": {\n",
    "          \"Edge_00\": {\"source\": \"Vertex_0000\", \"target\": \"Vertex_0004\", \"connectivity\": \"door\", ...},\n",
    "          ...\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    raw_vs: Dict[str, Dict[str, Any]] = data.get(\"vertices\", {}) or {}\n",
    "    raw_es: Dict[str, Dict[str, Any]] = data.get(\"edges\", {}) or {}\n",
    "\n",
    "    vertices: list[Vtx] = []\n",
    "    for vid, v in raw_vs.items():\n",
    "        label = v.get(\"node_name\") or v.get(\"roomtype\") or v.get(\"zone_name\") or str(vid)\n",
    "        x = float(v.get(\"x\", 0.0))\n",
    "        y = float(v.get(\"y\", 0.0))\n",
    "        z = float(v.get(\"z\", 0.0))\n",
    "        vertices.append(Vtx(id=vid, label=str(label), x=x, y=y, z=z, props=v))\n",
    "\n",
    "    edges: list[ERel] = []\n",
    "    for eid, e in raw_es.items():\n",
    "        src = str(e.get(\"source\"))\n",
    "        dst = str(e.get(\"target\"))\n",
    "        label = str(e.get(\"connectivity\") or e.get(\"label\") or \"adjacent\")\n",
    "        if not src or not dst:\n",
    "            continue\n",
    "        edges.append(ERel(src=src, dst=dst, label=label, props=e))\n",
    "\n",
    "    return vertices, edges\n",
    "\n",
    "# ---------------------\n",
    "# Kùzu helpers\n",
    "# ---------------------\n",
    "\n",
    "def ensure_schema(manager):\n",
    "    Kuzu.EnsureSchema(manager, silent=False)\n",
    "\n",
    "\n",
    "def upsert_graph(manager, graph_id: str, vertices: list[Vtx], edges: list[ERel], undirected: bool):\n",
    "    \"\"\"Insert a graph with vertices/edges into Kùzu using raw Cypher.\n",
    "    If undirected=True, we create two directed edges for each input edge.\n",
    "    \"\"\"\n",
    "    ensure_schema(manager)\n",
    "\n",
    "    # Clear prior graph with same id\n",
    "    manager.exec(\"MATCH (a:Vertex)-[r:Edge]->(b:Vertex) WHERE a.graph_id=$gid AND b.graph_id=$gid DELETE r;\",\n",
    "                 {\"gid\": graph_id}, write=True)\n",
    "    manager.exec(\"MATCH (v:Vertex) WHERE v.graph_id=$gid DELETE v;\", {\"gid\": graph_id}, write=True)\n",
    "    manager.exec(\"MATCH (g:Graph) WHERE g.id=$id DELETE g;\", {\"id\": graph_id}, write=True)\n",
    "\n",
    "    # Create Graph card\n",
    "    manager.exec(\n",
    "        \"\"\"\n",
    "        CREATE (g:Graph {id:$id, label:$label, num_nodes:$n, num_edges:$m, props:$props});\n",
    "        \"\"\",\n",
    "        {\"id\": graph_id, \"label\": graph_id, \"n\": len(vertices), \"m\": len(edges), \"props\": json.dumps({})},\n",
    "        write=True,\n",
    "    )\n",
    "\n",
    "    # Insert vertices\n",
    "\n",
    "    query = \"\"\"\n",
    "    CREATE (v:Vertex {\n",
    "        id:$id,\n",
    "        graph_id:$gid,\n",
    "        label:$label,\n",
    "        x:$x,\n",
    "        y:$y,\n",
    "        z:$z,\n",
    "        props:$props\n",
    "    });\n",
    "    \"\"\"\n",
    "\n",
    "    for v in vertices:\n",
    "        params = {\n",
    "                \"id\": f\"{graph_id}:{v.id}\",\n",
    "                \"gid\": graph_id,\n",
    "                \"label\": v.label,\n",
    "                \"x\": float(v.x),\n",
    "                \"y\": float(v.y),\n",
    "                \"z\": float(v.z),\n",
    "                \"props\": json.dumps(v.props),\n",
    "                }\n",
    "        manager.exec(query, params, write=True)\n",
    "    # Insert edges (directed; if undirected, add reverse)\n",
    "    for e in edges:\n",
    "        params = {\"a\": f\"{graph_id}:{e.src}\", \"b\": f\"{graph_id}:{e.dst}\", \"label\": e.label, \"props\": json.dumps(e.props)}\n",
    "        manager.exec(\n",
    "            \"\"\"\n",
    "            MATCH (va:Vertex {id:$a}), (vb:Vertex {id:$b})\n",
    "            CREATE (va)-[:Edge {label:$label, props:$props}]->(vb);\n",
    "            \"\"\",\n",
    "            params,\n",
    "            write=True,\n",
    "        )\n",
    "        if undirected:\n",
    "            manager.exec(\n",
    "                \"\"\"\n",
    "                MATCH (va:Vertex {id:$a}), (vb:Vertex {id:$b})\n",
    "                CREATE (vb)-[:Edge {label:$label, props:$props}]->(va);\n",
    "                \"\"\",\n",
    "                params,\n",
    "                write=True,\n",
    "            )\n",
    "\n",
    "# --- Small builders for the *working* graph we are constructing ---\n",
    "\n",
    "def create_graph_card_if_missing(manager, graph_id: str):\n",
    "    rows = manager.exec(\"MATCH (g:Graph {id:$id}) RETURN 1 LIMIT 1\", {\"id\": graph_id}, write=False) or []\n",
    "    if not rows:\n",
    "        manager.exec(\n",
    "            \"CREATE (g:Graph {id:$id, label:$id, num_nodes:0, num_edges:0, props:'{}'})\",\n",
    "            {\"id\": graph_id}, write=True)\n",
    "\n",
    "\n",
    "def create_vertex(manager, graph_id: str, local_id: str, label: str, props: Dict[str,Any] | None = None,\n",
    "                  x: float = 0.0, y: float = 0.0, z: float = 0.0):\n",
    "    create_graph_card_if_missing(manager, graph_id)\n",
    "    manager.exec(\n",
    "        \"\"\"\n",
    "        CREATE (:Vertex {id:$id, graph_id:$gid, label:$label, x:$x, y:$y, z:$z, props:$props});\n",
    "        \"\"\",\n",
    "        {\"id\": f\"{graph_id}:{local_id}\",\n",
    "         \"gid\": graph_id,\n",
    "         \"label\": label,\n",
    "         \"x\": float(x),\n",
    "         \"y\": float(y),\n",
    "         \"z\": float(z),\n",
    "         \"props\": json.dumps(props or {})},\n",
    "        write=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def edge_exists(manager, graph_id: str, a_local: str, b_local: str) -> bool:\n",
    "    rows = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex {id:$a})-[:Edge]->(b:Vertex {id:$b}) RETURN 1 LIMIT 1\n",
    "        \"\"\",\n",
    "        {\"a\": f\"{graph_id}:{a_local}\", \"b\": f\"{graph_id}:{b_local}\"}, write=False,\n",
    "    ) or []\n",
    "    return len(rows) > 0\n",
    "\n",
    "\n",
    "def create_edge_bidirectional(manager, graph_id: str, a_local: str, b_local: str, label: str = \"suggested\",\n",
    "                              props: Dict[str,Any] | None = None):\n",
    "    a_local = a_local.split()[0]\n",
    "    b_local = b_local.split()[0]\n",
    "    if edge_exists(manager, graph_id, a_local, b_local) and edge_exists(manager, graph_id, b_local, a_local):\n",
    "        print(\"Warning: Edge already exists. Skipping.\")\n",
    "        return False\n",
    "    manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex {id:$a}), (b:Vertex {id:$b})\n",
    "        CREATE (a)-[:Edge {label:$lbl, props:$props}]->(b),\n",
    "               (b)-[:Edge {label:$lbl, props:$props}]->(a);\n",
    "        \"\"\",\n",
    "        {\"a\": f\"{graph_id}:{a_local}\", \"b\": f\"{graph_id}:{b_local}\", \"lbl\": label, \"props\": json.dumps(props or {})},\n",
    "        write=True,\n",
    "    )\n",
    "    return True\n",
    "\n",
    "\n",
    "def list_working_nodes(manager, graph_id: str) -> list[Dict[str,str]]:\n",
    "    rows = manager.exec(\n",
    "        \"MATCH (v:Vertex) WHERE v.graph_id=$gid RETURN v.id AS id, v.label AS label, v.props AS props ORDER BY id\",\n",
    "        {\"gid\": graph_id}, write=False\n",
    "    ) or []\n",
    "    return [{\"id\": r[\"id\"].split(\":\",1)[1],\n",
    "             \"label\": r.get(\"label\",\"\"),\n",
    "             \"props\": r.get(\"props\")} for r in rows]\n",
    "\n",
    "def list_working_edges(manager, graph_id: str) -> list[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Returns all edges in the current working graph as a list of dicts:\n",
    "    [{'a': 'n0', 'b': 'n1', 'label': 'suggested', 'props': {...}}, ...]\n",
    "    \"\"\"\n",
    "    rows = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex)-[r:Edge]->(b:Vertex)\n",
    "        WHERE a.graph_id=$gid AND b.graph_id=$gid\n",
    "        RETURN a.id AS a, b.id AS b, r.label AS label, r.props AS props\n",
    "        \"\"\",\n",
    "        {\"gid\": graph_id}, write=False\n",
    "    ) or []\n",
    "    return [\n",
    "        {\n",
    "            \"a\": r[\"a\"].split(\":\", 1)[1],\n",
    "            \"b\": r[\"b\"].split(\":\", 1)[1],\n",
    "            \"label\": r.get(\"label\", \"\"),\n",
    "            \"props\": r.get(\"props\", {}),\n",
    "        }\n",
    "        for r in rows\n",
    "    ]\n",
    "\n",
    "def max_neighbors_for_label(\n",
    "    manager,\n",
    "    label_query: str,\n",
    "    *,\n",
    "    undirected: bool = True,\n",
    "    substring: bool = True,\n",
    "    selection_mode: str = \"first\",            # \"first\" | \"max_out_degree_within_graph\"\n",
    "    include_graph_ids: set[str] | None = None,\n",
    "    exclude_graph_ids_prefixes: tuple[str, ...] = (\"work_\",),\n",
    "    exclude_edge_labels: set[str] = frozenset({\"suggested\"})\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Return the maximum number of unique neighbors for the label across the DB,\n",
    "    but constrain to **one representative vertex per graph** to avoid inflation\n",
    "    when a graph contains multiple vertices with the same label.\n",
    "\n",
    "    Parameters mirror the earlier function, with `selection_mode` controlling how\n",
    "    the per-graph representative is chosen:\n",
    "      - \"first\": smallest v.id (stable & fast)\n",
    "      - \"max_out_degree_within_graph\": pick the matching vertex that has the\n",
    "        highest out-degree (using filtered edges), then count its neighbors\n",
    "        (undirected or directed per `undirected` flag).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Fetch vertices\n",
    "    rows_v = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (v:Vertex)\n",
    "        RETURN v.id AS id, v.graph_id AS gid, v.label AS label\n",
    "        \"\"\",\n",
    "        {}, write=False\n",
    "    ) or []\n",
    "\n",
    "    def graph_allowed(gid: str) -> bool:\n",
    "        if include_graph_ids is not None:\n",
    "            return gid in include_graph_ids\n",
    "        return not any(gid.startswith(pref) for pref in exclude_graph_ids_prefixes)\n",
    "\n",
    "    needle = (label_query or \"\").strip().lower()\n",
    "    # group matching vertices by graph id\n",
    "    matches_by_gid: dict[str, list[str]] = {}\n",
    "    labels_by_vid: dict[str, str] = {}\n",
    "\n",
    "    for r in rows_v:\n",
    "        vid = r[\"id\"]\n",
    "        gid = r.get(\"gid\", \"\")\n",
    "        lbl = str(r.get(\"label\") or \"\")\n",
    "        if not graph_allowed(gid):\n",
    "            continue\n",
    "        labels_by_vid[vid] = lbl\n",
    "        lbln = lbl.strip().lower()\n",
    "        ok = (needle in lbln) if substring else (lbln == needle)\n",
    "        if ok:\n",
    "            matches_by_gid.setdefault(gid, []).append(vid)\n",
    "\n",
    "    if not matches_by_gid:\n",
    "        return 0\n",
    "\n",
    "    # --- Fetch edges once (filtered)\n",
    "    rows_e = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex)-[r:Edge]->(b:Vertex)\n",
    "        RETURN a.id AS a, a.graph_id AS agid, b.id AS b, b.graph_id AS bgid, r.label AS rlabel\n",
    "        \"\"\",\n",
    "        {}, write=False\n",
    "    ) or []\n",
    "\n",
    "    edges = []\n",
    "    for r in rows_e:\n",
    "        a, agid = r[\"a\"], r.get(\"agid\", \"\")\n",
    "        b, bgid = r[\"b\"], r.get(\"bgid\", \"\")\n",
    "        if not (graph_allowed(agid) and graph_allowed(bgid)):\n",
    "            continue\n",
    "        if str(r.get(\"rlabel\") or \"\") in exclude_edge_labels:\n",
    "            continue\n",
    "        edges.append((a, b))\n",
    "\n",
    "    # Pre-index neighbors for quick degree checks\n",
    "    out_neighbors: dict[str, set[str]] = {}\n",
    "    in_neighbors: dict[str, set[str]] = {}\n",
    "    for a, b in edges:\n",
    "        out_neighbors.setdefault(a, set()).add(b)\n",
    "        in_neighbors.setdefault(b, set()).add(a)\n",
    "\n",
    "    # Choose exactly one representative per graph\n",
    "    rep_ids: set[str] = set()\n",
    "    if selection_mode == \"max_out_degree_within_graph\":\n",
    "        for gid, vids in matches_by_gid.items():\n",
    "            # pick the vertex with max OUT-degree (based on filtered edges)\n",
    "            best_vid = max(vids, key=lambda v: len(out_neighbors.get(v, set())))\n",
    "            rep_ids.add(best_vid)\n",
    "    else:  # \"first\" (deterministic by min id)\n",
    "        for gid, vids in matches_by_gid.items():\n",
    "            rep_ids.add(min(vids))\n",
    "\n",
    "    # Compute neighbor counts for representatives only\n",
    "    def neighbor_set(v: str) -> set[str]:\n",
    "        if undirected:\n",
    "            return out_neighbors.get(v, set()) | in_neighbors.get(v, set())\n",
    "        return out_neighbors.get(v, set())\n",
    "\n",
    "    return max((len(neighbor_set(v)) for v in rep_ids), default=0)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Global candidate list (across *all* graphs)\n",
    "# ---------------------\n",
    "\n",
    "def _working_vertices_and_edges(manager, working_graph_id: str):\n",
    "    \"\"\"Return (vertices, edges) for the working graph.\n",
    "       vertices: [{id_local, label, props}]\n",
    "       edges:    [(a_local, b_local)]   (directed, as stored)\n",
    "    \"\"\"\n",
    "    rows_v = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (v:Vertex) WHERE v.graph_id=$gid\n",
    "        RETURN v.id AS id, v.label AS label, v.props AS props\n",
    "        \"\"\",\n",
    "        {\"gid\": working_graph_id}, write=False\n",
    "    ) or []\n",
    "    rows_e = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex)-[:Edge]->(b:Vertex)\n",
    "        WHERE a.graph_id=$gid AND b.graph_id=$gid\n",
    "        RETURN a.id AS a, b.id AS b\n",
    "        \"\"\",\n",
    "        {\"gid\": working_graph_id}, write=False\n",
    "    ) or []\n",
    "\n",
    "    vertices = [{\"id_local\": r[\"id\"].split(\":\", 1)[1],\n",
    "                 \"label\": r.get(\"label\", \"\"),\n",
    "                 \"props\": r.get(\"props\", {})} for r in rows_v]\n",
    "    edges = [(r[\"a\"].split(\":\", 1)[1], r[\"b\"].split(\":\", 1)[1]) for r in rows_e]\n",
    "    return vertices, edges\n",
    "\n",
    "\n",
    "def _anchor_labels_with_degree_cap(manager, working_graph_id: str, oracle: dict) -> list[str]:\n",
    "    \"\"\"Compute *undirected* degree per node in working graph and return labels for nodes with deg ≤ max_deg.\"\"\"\n",
    "    vertices, edges = _working_vertices_and_edges(manager, working_graph_id)\n",
    "\n",
    "    # Build undirected adjacency (so an edge a->b and b->a counts as ONE connection)\n",
    "    adj = {v[\"id_local\"]: set() for v in vertices}\n",
    "    for a, b in edges:\n",
    "        # treat each directed edge as undirected; add both ways\n",
    "        adj.setdefault(a, set()).add(b)\n",
    "        adj.setdefault(b, set()).add(a)\n",
    "\n",
    "    # Degree = number of unique neighbors\n",
    "    id_to_label = {v[\"id_local\"]: v[\"label\"] for v in vertices}\n",
    "    anchor_labels = []\n",
    "    print(f\" The following nodes have less connections than what the maximum found in the graph database so they will be considered for expansion:\")\n",
    "    for vid, nbrs in adj.items():\n",
    "        deg = len(nbrs)\n",
    "        anchor_label = id_to_label.get(vid, \"\")\n",
    "        if oracle.get(anchor_label, 1) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            max_degree = max_neighbors_for_label(manager, anchor_label) \n",
    "            if deg <= max_degree:\n",
    "                anchor_label = id_to_label.get(vid, \"\")\n",
    "                print(f\"  . {anchor_label} (No. Connections: {deg}, Max found in DB: {max_degree}) \")\n",
    "                anchor_labels.append(anchor_label)\n",
    "            else:\n",
    "                oracle[anchor_label] = 0\n",
    "\n",
    "    # Clean, dedupe, keep non-empty\n",
    "    return sorted({lbl for lbl in anchor_labels if lbl}), oracle\n",
    "\n",
    "\n",
    "def fetch_all_pairs(manager, working_graph_id: str, oracle:dict) -> list[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Enhanced: Use ONLY input nodes (anchors) from the current working graph whose undirected degree ≤ n,\n",
    "    then fetch (a.label, b.label) pairs from the *entire* dataset, filtered to those anchors.\n",
    "    Returns list of (a_label, b_label) pairs.\n",
    "    \"\"\"\n",
    "    # 1) Get anchor labels from the working graph, filtered by degree cap\n",
    "    anchors, oracle = _anchor_labels_with_degree_cap(manager, working_graph_id, oracle)\n",
    "    if not anchors:\n",
    "        return [], {}  # nothing to expand from\n",
    "\n",
    "    anchors_lower = {a.lower() for a in anchors}\n",
    "\n",
    "    # 2) Pull all pairs across all graphs (no graph_id filter), then filter by anchor labels in Python\n",
    "    rows = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex)-[:Edge]->(b:Vertex)\n",
    "        RETURN a.label AS a_label, b.label AS b_label\n",
    "        \"\"\",\n",
    "        {}, write=False\n",
    "    ) or []\n",
    "\n",
    "    pairs = []\n",
    "    for r in rows:\n",
    "        a_lab = str(r.get(\"a_label\") or \"\").strip()\n",
    "        b_lab = str(r.get(\"b_label\") or \"\").strip()\n",
    "        if a_lab and b_lab and a_lab.lower() in anchors_lower:\n",
    "            pairs.append((a_lab, b_lab))\n",
    "\n",
    "    return pairs, oracle\n",
    "\n",
    "def candidate_counts_for_labels(manager, working_graph_id: str, labels: list[str], oracle: dict) -> list[tuple[str,int]]:\n",
    "    \"\"\"Aggregate neighbor label frequencies across *all* graphs for any a.label in labels (case-insensitive).\"\"\"\n",
    "    pairs, oracle = fetch_all_pairs(manager, working_graph_id = working_graph_id, oracle=oracle)\n",
    "    label_set = {l.lower() for l in labels}\n",
    "    cnt = Counter(b for (a,b) in pairs if a.lower() in label_set)\n",
    "    if \"\" in cnt:\n",
    "        del cnt[\"\"]\n",
    "    return sorted(cnt.items(), key=lambda kv: (-kv[1], kv[0])), oracle\n",
    "\n",
    "# ---------------------\n",
    "# Seed props copier — find best example for a label across all graphs\n",
    "# ---------------------\n",
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "from statistics import median, mean\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "def find_best_example_for_label(manager, attach_to, label_substring: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Search the entire Kùzu DB for occurrences of edges (attach_to_label -> target_label).\n",
    "    Use the most-popular direction (by angle bin) and typical distance (median within that bin)\n",
    "    to compute a RECOMMENDED coordinate for the new node as an offset from the given attach_to node.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    manager : Kùzu manager\n",
    "    attach_to : str | dict\n",
    "        - str: label of the attach node (e.g., \"Entrance\"). Anchor coords default to (0,0,0).\n",
    "        - dict: must include at least {\"label\": \"...\"} and *optionally* {\"x\":..,\"y\":..,\"z\":..}\n",
    "                If x/y/z are present, they are used as the anchor for the recommended offset.\n",
    "    label_substring : str\n",
    "        Target node label (first word is used for matching, e.g., \"Living\" from \"Living Room\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict or None:\n",
    "      {\n",
    "        \"best_example\": {\"gid\",\"id\",\"label\",\"x\",\"y\",\"z\",\"props\"},\n",
    "        \"recommended\": {\"x\": float, \"y\": float, \"z\": float, \"distance\": float}\n",
    "      }\n",
    "      or None if no corpus matches are found.\n",
    "    \"\"\"\n",
    "    # Normalize inputs\n",
    "    if isinstance(attach_to, str):\n",
    "        attach_to_label = attach_to\n",
    "        anchor_x, anchor_y, anchor_z = 0.0, 0.0, 0.0\n",
    "    elif isinstance(attach_to, dict):\n",
    "        attach_to_label = attach_to.get(\"label\", \"\")\n",
    "        anchor_x = float(attach_to.get(\"x\", 0.0))\n",
    "        anchor_y = float(attach_to.get(\"y\", 0.0))\n",
    "        anchor_z = float(attach_to.get(\"z\", 0.0))\n",
    "    else:\n",
    "        attach_to_label, anchor_x, anchor_y, anchor_z = \"\", 0.0, 0.0, 0.0\n",
    "\n",
    "    # Only use first word (e.g., \"Living\" from \"Living Room\")\n",
    "    if attach_to_label == \"\":\n",
    "        a_word = \"\"\n",
    "    else:\n",
    "        a_word = (attach_to_label or \"\").split()[0].lower()\n",
    "    if label_substring == \"\":\n",
    "        b_word = \"\"\n",
    "    else:\n",
    "        b_word = (label_substring or \"\").split()[0].lower()\n",
    "\n",
    "    # 1) Pull ALL (a -> b) pairs with coordinates\n",
    "    rows = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex)-[:Edge]->(b:Vertex)\n",
    "        RETURN\n",
    "          a.graph_id AS agid, a.id AS aid, a.label AS a_label, a.x AS ax, a.y AS ay, a.z AS az,\n",
    "          b.graph_id AS bgid, b.id AS bid, b.label AS b_label, b.x AS bx, b.y AS by, b.z AS bz, b.props AS bprops\n",
    "        \"\"\",\n",
    "        {}, write=False\n",
    "    ) or []\n",
    "\n",
    "    # 2) Filter in Python (case-insensitive, first-word heuristic)\n",
    "    pairs = []\n",
    "    for r in rows:\n",
    "        a_lab = str(r.get(\"a_label\") or \"\")\n",
    "        b_lab = str(r.get(\"b_label\") or \"\")\n",
    "        if (a_word in a_lab.lower()) and (b_word in b_lab.lower()):\n",
    "            ax, ay, az = float(r.get(\"ax\", 0.0)), float(r.get(\"ay\", 0.0)), float(r.get(\"az\", 0.0))\n",
    "            bx, by, bz = float(r.get(\"bx\", 0.0)), float(r.get(\"by\", 0.0)), float(r.get(\"bz\", 0.0))\n",
    "            dx, dy, dz = (bx - ax), (by - ay), (bz - az)\n",
    "            dist = math.sqrt(dx*dx + dy*dy + dz*dz)\n",
    "            pairs.append({\n",
    "                \"agid\": r.get(\"agid\"), \"aid\": r.get(\"aid\"), \"a_label\": a_lab, \"ax\": ax, \"ay\": ay, \"az\": az,\n",
    "                \"bgid\": r.get(\"bgid\"), \"bid\": r.get(\"bid\"), \"b_label\": b_lab, \"bx\": bx, \"by\": by, \"bz\": bz,\n",
    "                \"bprops\": r.get(\"bprops\", {}),\n",
    "                \"dx\": dx, \"dy\": dy, \"dz\": dz, \"dist\": dist\n",
    "            })\n",
    "\n",
    "    if not pairs:\n",
    "        return None\n",
    "\n",
    "    # 3) Choose a \"best example\" node for the target label\n",
    "    target_counts = Counter(p[\"b_label\"] for p in pairs)\n",
    "    best_target_label, _ = max(target_counts.items(), key=lambda kv: kv[1])\n",
    "    best_row = next(p for p in pairs if p[\"b_label\"] == best_target_label)\n",
    "    best_example = {\n",
    "        \"gid\": best_row[\"bgid\"],\n",
    "        \"id\":  best_row[\"bid\"],\n",
    "        \"label\": best_row[\"b_label\"],\n",
    "        \"x\": best_row[\"bx\"], \"y\": best_row[\"by\"], \"z\": best_row[\"bz\"],\n",
    "        \"props\": best_row.get(\"bprops\", {})\n",
    "    }\n",
    "\n",
    "    # 4) Determine most-popular direction bin and typical distance\n",
    "    DIR_BIN_COUNT = 16     # 22.5-degree bins\n",
    "    DIST_BIN_SIZE = 0.5    # meters\n",
    "\n",
    "    dir_bins = []\n",
    "    dist_bins = []\n",
    "    for p in pairs:\n",
    "        ang = math.degrees(math.atan2(p[\"dy\"], p[\"dx\"])) % 360.0\n",
    "        dir_bin = int((ang / 360.0) * DIR_BIN_COUNT) % DIR_BIN_COUNT\n",
    "        dir_bins.append(dir_bin)\n",
    "        dist_bins.append(int(p[\"dist\"] / DIST_BIN_SIZE))\n",
    "\n",
    "    # Mode direction bin and mode distance bin\n",
    "    dir_mode_bin, _ = Counter(dir_bins).most_common(1)[0]\n",
    "\n",
    "    # Compute a representative unit direction from vectors in the mode direction bin\n",
    "    sel_vectors = []\n",
    "    for p, db in zip(pairs, dir_bins):\n",
    "        if db == dir_mode_bin and p[\"dist\"] > 1e-9:\n",
    "            ux, uy, uz = p[\"dx\"]/p[\"dist\"], p[\"dy\"]/p[\"dist\"], p[\"dz\"]/p[\"dist\"]\n",
    "            sel_vectors.append((ux, uy, uz))\n",
    "\n",
    "    if sel_vectors:\n",
    "        mx = sum(v[0] for v in sel_vectors)/len(sel_vectors)\n",
    "        my = sum(v[1] for v in sel_vectors)/len(sel_vectors)\n",
    "        mz = sum(v[2] for v in sel_vectors)/len(sel_vectors)\n",
    "        norm = math.sqrt(mx*mx + my*my + mz*mz) or 1.0\n",
    "        unit_dir = (mx/norm, my/norm, mz/norm)\n",
    "    else:\n",
    "        unit_dir = (1.0, 0.0, 0.0)  # fallback\n",
    "\n",
    "    # Typical distance: median of distances in that same direction bin (robust)\n",
    "    sel_dists = [p[\"dist\"] for p, db in zip(pairs, dir_bins) if db == dir_mode_bin]\n",
    "    rec_dist = median(sel_dists) if sel_dists else 0.0\n",
    "\n",
    "    # 5) Compute recommended coordinates as an offset from the provided attach_to anchor\n",
    "    rx = anchor_x + unit_dir[0] * rec_dist\n",
    "    ry = anchor_y + unit_dir[1] * rec_dist\n",
    "    rz = anchor_z + unit_dir[2] * rec_dist\n",
    "\n",
    "    return {\n",
    "        \"best_example\": best_example,\n",
    "        \"recommended\": {\"x\": rx, \"y\": ry, \"z\": rz, \"distance\": rec_dist}\n",
    "    }\n",
    "\n",
    "# ---------------------\n",
    "# TopologicPy graph snapshots (FULL graph export)\n",
    "# ---------------------\n",
    "\n",
    "def _build_tp_graph(vertices: list[Dict[str, Any]], edges: list[Tuple[str, str]]) -> Any:\n",
    "    \"\"\"Return a TopologicPy Graph if available; otherwise a plain dict with vertices/edges.\n",
    "    Vertices: list of dicts {id, label, x, y, z, props}\n",
    "    Edges: list of (src_local_id, dst_local_id)\n",
    "    \"\"\"\n",
    "    import random\n",
    "\n",
    "    if _TOPOLOGICPY_AVAILABLE:\n",
    "        id_to_vertex: Dict[str, Any] = {}\n",
    "        tp_vertices: list[Any] = []\n",
    "        for v in vertices:\n",
    "            x = random.uniform(0,10)\n",
    "            y = random.uniform(0,10)\n",
    "            z = 0\n",
    "            vx = TPVertex.ByCoordinates(x,y,z)\n",
    "            # Attach dictionary from props (inherited from graph DB)\n",
    "            props = v.get(\"props\", {})\n",
    "            if isinstance(props, str):\n",
    "                try:\n",
    "                    props = json.loads(props)\n",
    "                except Exception:\n",
    "                    props = {\"_raw_props\": props}\n",
    "            if isinstance(props, dict) and props:\n",
    "                keys = list(props.keys())\n",
    "                vals = list(props.values())\n",
    "                try:\n",
    "                    d = TPDict.ByKeysValues(keys, vals)\n",
    "                    vx = TPTopology.SetDictionary(vx, d)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            id_to_vertex[v[\"id\"]] = vx\n",
    "            tp_vertices.append(vx)\n",
    "        tp_edges: list[Any] = []\n",
    "        for (s, t) in edges:\n",
    "            sv = id_to_vertex.get(s)\n",
    "            tv = id_to_vertex.get(t)\n",
    "            if sv is not None and tv is not None:\n",
    "                tp_edges.append(TPEdge.ByStartVertexEndVertex(sv, tv))\n",
    "        try:\n",
    "            return TPGraph.ByVerticesEdges(tp_vertices, tp_edges)\n",
    "        except Exception:\n",
    "            return {\"vertices\": tp_vertices, \"edges\": tp_edges}\n",
    "    else:\n",
    "        return {\"vertices\": vertices, \"edges\": edges}\n",
    "\n",
    "\n",
    "def snapshot_full_graph(manager, graph_id: str) -> Any:\n",
    "    \"\"\"Export the **entire current graph** from Kùzu and return a TopologicPy Graph (if available) or a dict.\n",
    "    Ensures vertex dictionaries are inherited from DB `props`.\n",
    "    \"\"\"\n",
    "    import random\n",
    "\n",
    "    rows_v = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (v:Vertex)\n",
    "        WHERE v.graph_id=$gid\n",
    "        RETURN v.id AS id, v.label AS label, v.x AS x, v.y AS y, v.z AS z, v.props AS props\n",
    "        \"\"\",\n",
    "        {\"gid\": graph_id}, write=False,\n",
    "    ) or []\n",
    "\n",
    "    rows_e = manager.exec(\n",
    "        \"\"\"\n",
    "        MATCH (a:Vertex)-[:Edge]->(b:Vertex)\n",
    "        WHERE a.graph_id=$gid AND b.graph_id=$gid\n",
    "        RETURN a.id AS a, b.id AS b\n",
    "        \"\"\",\n",
    "        {\"gid\": graph_id}, write=False,\n",
    "    ) or []\n",
    "\n",
    "    verts = [{\n",
    "        \"id\": r[\"id\"].split(\":\",1)[1],\n",
    "        \"label\": r.get(\"label\",\"\"),\n",
    "        \"x\": r.get(\"x\",random.uniform(0,100)*0.1),\n",
    "        \"y\": r.get(\"y\",random.uniform(0,100)*0.1),\n",
    "        \"z\": r.get(\"z\",0.0),\n",
    "        \"props\": r.get(\"props\", {})\n",
    "    } for r in rows_v]\n",
    "    eds = [(r[\"a\"].split(\":\",1)[1], r[\"b\"].split(\":\",1)[1]) for r in rows_e]\n",
    "    return _build_tp_graph(verts, eds)\n",
    "\n",
    "# ---------------------\n",
    "# Global-candidate logic + LLM action picker — single action per iteration\n",
    "# ---------------------\n",
    "\n",
    "def _heuristic_pick_action(current_nodes: list[Dict[str,str]], candidate_counts: list[tuple[str,int]]):\n",
    "    existing_labels = {n[\"label\"].lower() for n in current_nodes}\n",
    "    # Try ADD a high-frequency label not already present\n",
    "    for lab, _ in candidate_counts:\n",
    "        if lab.lower() not in existing_labels:\n",
    "            attach_to = current_nodes[0][\"id\"] if current_nodes else None\n",
    "            return {\"action\": \"add\", \"new_label\": lab, \"attach_to\": attach_to}\n",
    "    # Else CONNECT first two nodes if any\n",
    "    if len(current_nodes) >= 2:\n",
    "        return {\"action\": \"connect\", \"a\": current_nodes[0][\"id\"], \"b\": current_nodes[1][\"id\"]}\n",
    "    return {\"action\": \"stop\", \"reason\": \"No candidates and insufficient nodes to connect.\"}\n",
    "\n",
    "\n",
    "def llm_pick_action(description,\n",
    "                    current_nodes: list[Dict[str,str]],\n",
    "                    candidate_counts: list[tuple[str,int]],\n",
    "                    current_edges: list\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Ask Claude to choose exactly one action. It knows the candidate list is frequency-sorted\n",
    "    but may propose a new label not in the list. Returns one of:\n",
    "      {\"action\":\"add\",\"new_label\":\"Kitchen\",\"attach_to\":\"<existing_local_id>\"}\n",
    "      {\"action\":\"connect\",\"a\":\"<existing_local_id>\",\"b\":\"<existing_local_id>\"}\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    if (not anthropic_available) or (os.getenv(\"ANTHROPIC_API_KEY\") is None):\n",
    "        return _heuristic_pick_action(current_nodes, candidate_counts)\n",
    "\n",
    "    try:\n",
    "        # Initialize Claude client\n",
    "        client = Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "        model = os.getenv(\"CLAUDE_MODEL\", \"claude-sonnet-4-20250514\")\n",
    "        \n",
    "        sys_prompt = (\n",
    "            f\"You are designing an adjacency graph that represents {description}. You receive: \"\n",
    "            \"(1) A description of what the graph represents, (2) the current graph's nodes, (2) the current graph's edges, and (3) a frequency-sorted list of candidate neighbor labels \"\n",
    "            f\"aggregated from many example graphs. Build a list of nodes usually found in a graph that represents {description}.\"\n",
    "            \"You may choose from the provided list of candidate node labels or propose a new label from the list that you built.\"\n",
    "            \"Choose exactly ONE action: either ADD a new node with a single connection to an existing node, \"\n",
    "            \"or CONNECT two existing nodes, or STOP if no further action is needed. Include a reason for stopping.\"\n",
    "            \"Do not repeat previous suggestions.\"\n",
    "            \"Return ONLY valid JSON (no markdown, no extra text) with one of these forms:\\n\"\n",
    "            \"{\\\"action\\\":\\\"add\\\",\\\"new_label\\\":\\\"<string>\\\",\\\"attach_to\\\":\\\"<existing_local_id> (<string>)\\\"}\\n\"\n",
    "            \"{\\\"action\\\":\\\"connect\\\",\\\"a\\\":\\\"<existing_local_id> (<string>) \\\",\\\"b\\\":\\\"<existing_local_id> (<string>)\\\"}\\n\"\n",
    "            \"{\\\"action\\\":\\\"stop\\\",\\\"reason\\\":\\\"<string> \\\"}\"\n",
    "        )\n",
    "        \n",
    "        user_payload = {\n",
    "            \"description\": description,\n",
    "            \"current_nodes\": current_nodes,\n",
    "            \"current_edges\": current_edges or [],\n",
    "            \"candidate_counts\": candidate_counts,\n",
    "            \"note\": \"The candidate list is sorted by frequency across many graphs; you may propose a new label.\"\n",
    "        }\n",
    "        \n",
    "        # Call Claude API\n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=1024,\n",
    "            temperature=0.3,\n",
    "            system=sys_prompt,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": json.dumps(user_payload, indent=2)\n",
    "            }]\n",
    "        )\n",
    "        \n",
    "        # Extract response\n",
    "        text = message.content[0].text.strip()\n",
    "        \n",
    "        # Parse JSON (handle markdown code blocks if present)\n",
    "        if text.startswith(\"```\"):\n",
    "            lines = text.split(\"\\n\")\n",
    "            text = \"\\n\".join(lines[1:-1]) if len(lines) > 2 else text\n",
    "        \n",
    "        # Extract JSON by finding first { and last }\n",
    "        start_idx = text.find(\"{\")\n",
    "        end_idx = text.rfind(\"}\")\n",
    "        if start_idx != -1 and end_idx != -1:\n",
    "            text = text[start_idx:end_idx+1]\n",
    "        \n",
    "        try:\n",
    "            json_data = json.loads(text)\n",
    "            json_action = json_data['action']\n",
    "            json_a_label = json_data.get('new_label', json_data.get('a'))\n",
    "            json_b_label = json_data.get('attach_to', json_data.get('b'))\n",
    "            print_b_label = copy.copy(json_b_label)\n",
    "            print_b_label = print_b_label.split()[1].strip(\"()\") if isinstance(print_b_label, str) and len(print_b_label.split()) > 1 else print_b_label\n",
    "            \n",
    "            if \"add\" in json_action.lower():\n",
    "                print(f\" I suggest that you {json_action.lower()} '{json_a_label}' and connect it to '{print_b_label}'\")\n",
    "            elif \"connect\" in json_action.lower():\n",
    "                print(f\" I suggest that you {json_action.lower()} '{json_a_label}' to '{print_b_label}'\")\n",
    "            elif \"stop\" in json_action.lower():\n",
    "                print(\" I suggest that you stop.\")\n",
    "            else:\n",
    "                print(\" I don't know what to suggest.\")\n",
    "\n",
    "            return json_data\n",
    "        except Exception:\n",
    "            return _heuristic_pick_action(current_nodes, candidate_counts)\n",
    "    except Exception as e:\n",
    "        print(f\"Claude API error: {e}\")\n",
    "        return _heuristic_pick_action(current_nodes, candidate_counts)\n",
    "\n",
    "# ---------------------\n",
    "# Builder loop — seed from dataset example, then iterate\n",
    "# ---------------------\n",
    "\n",
    "def import_folder_to_kuzu(json_folder: str, manager, undirected: bool = True) -> List[str]:\n",
    "    graph_ids: List[str] = []\n",
    "    for path in sorted(glob.glob(os.path.join(json_folder, \"*.json\"))):\n",
    "        verts, edges = load_topologic_graph(path)\n",
    "        gid = os.path.splitext(os.path.basename(path))[0]\n",
    "        upsert_graph(manager, gid, verts, edges, undirected=undirected)\n",
    "        graph_ids.append(gid)\n",
    "    return graph_ids\n",
    "\n",
    "def init_working_graph(manager, working_graph_id: str, start_label: str):\n",
    "    \"\"\"Create a new working graph with a seed node copied from the best dataset example for start_label.\"\"\"\n",
    "    # reset working graph\n",
    "    manager.exec(\"MATCH (a:Vertex)-[r:Edge]->(b:Vertex) WHERE a.graph_id=$gid AND b.graph_id=$gid DELETE r;\",\n",
    "                 {\"gid\": working_graph_id}, write=True)\n",
    "    manager.exec(\"MATCH (v:Vertex) WHERE v.graph_id=$gid DELETE v;\", {\"gid\": working_graph_id}, write=True)\n",
    "    manager.exec(\"MATCH (g:Graph) WHERE g.id=$id DELETE g;\", {\"id\": working_graph_id}, write=True)\n",
    "    create_graph_card_if_missing(manager, working_graph_id)\n",
    "\n",
    "    best_example_dict = find_best_example_for_label(manager, attach_to=None, label_substring = start_label)\n",
    "    if best_example_dict is not None:\n",
    "        ex = best_example_dict['best_example']\n",
    "    else:\n",
    "        ex = None\n",
    "    if ex is None:\n",
    "        # fallback: minimal seed\n",
    "        create_vertex(manager, working_graph_id, local_id=\"n0\", label=start_label,\n",
    "                      props={\"source\": \"seed\", \"label\": start_label}, x=0.0, y=0.0, z=0.0)\n",
    "        return\n",
    "\n",
    "    # parse props if string\n",
    "    props = ex.get(\"props\", {})\n",
    "    if isinstance(props, str):\n",
    "        try:\n",
    "            props = json.loads(props)\n",
    "        except Exception:\n",
    "            props = {\"_raw_props\": props}\n",
    "\n",
    "    # enrich props with provenance\n",
    "    props = dict(props or {})\n",
    "    props.update({\n",
    "        \"source\": \"seed_from_dataset\",\n",
    "        \"matched_query\": start_label,\n",
    "        \"matched_label\": ex.get(\"label\",\"\"),\n",
    "        \"matched_graph_id\": ex.get(\"gid\",\"\"),\n",
    "        \"matched_vertex_id\": ex.get(\"id\",\"\"),\n",
    "    })\n",
    "\n",
    "    create_vertex(manager, working_graph_id, local_id=\"n0\", label=ex.get(\"label\", start_label),\n",
    "                  props=props, x=float(ex.get(\"x\",0.0)), y=float(ex.get(\"y\",0.0)), z=float(ex.get(\"z\",0.0)))\n",
    "\n",
    "\n",
    "def graphrag_build_loop(manager, \n",
    "                        working_graph_id: str,\n",
    "                        start_label: str,\n",
    "                        description: str,\n",
    "                        max_steps: int = 8,\n",
    "                        patience: int = 2,\n",
    "                        max_connections: int = 2) -> Dict[str,Any]:\n",
    "    \"\"\"\n",
    "    New logic:\n",
    "      - Start a fresh working graph; the seed node copies props from the best dataset example for `start_label`.\n",
    "      - Iteratively:\n",
    "          * Build global candidate list from ALL graphs using labels present in the working graph.\n",
    "          * Ask LLM to choose exactly one action (ADD or CONNECT) — it may propose a label not in the list.\n",
    "          * Apply action to working graph (may create node or connect existing nodes).\n",
    "          * Snapshot the full working graph.\n",
    "      - Stop at max_steps or if no effective change occurs.\n",
    "      - Patience: The maximum number of no effective change before giving up and stopping\n",
    "    Returns: { 'snapshots': [...], 'actions': [...], 'reason': str }\n",
    "    \"\"\"\n",
    "    init_working_graph(manager, working_graph_id, start_label)\n",
    "    snapshots = [snapshot_full_graph(manager, working_graph_id)]\n",
    "    actions_log: list[Dict[str,Any]] = []\n",
    "\n",
    "    no_action = 0\n",
    "    oracle = {}\n",
    "    for step in range(1, max_steps+1):\n",
    "        print(\"STEP:\", step)\n",
    "        current_nodes = list_working_nodes(manager, working_graph_id)\n",
    "        current_edges = list_working_edges(manager, working_graph_id)\n",
    "        labels_now = [n[\"label\"] for n in current_nodes]\n",
    "        cand_counts, oracle = candidate_counts_for_labels(manager=manager,\n",
    "                                                  working_graph_id=working_graph_id,\n",
    "                                                  labels=labels_now,\n",
    "                                                  oracle = oracle)\n",
    "\n",
    "        action = llm_pick_action(description = description,\n",
    "                                 current_nodes = current_nodes,\n",
    "                                 candidate_counts = cand_counts,\n",
    "                                 current_edges= current_edges)\n",
    "            \n",
    "\n",
    "        if action.get(\"action\") == \"add\":\n",
    "            new_label = str(action.get(\"new_label\") or \"\").strip()\n",
    "            attach_to = str(action.get(\"attach_to\") or \"\").strip().split()[0]\n",
    "            # ensure attach_to is a valid existing local id; if not, pick first\n",
    "            existing_ids = {n[\"id\"] for n in current_nodes}\n",
    "            if attach_to not in existing_ids:\n",
    "                print(\"Warning: Could not find attach_to in existing_ids\")\n",
    "                attach_to = next(iter(existing_ids), None)\n",
    "            if new_label and attach_to:\n",
    "                new_id = f\"n{len(current_nodes)}\"\n",
    "                # attempt to copy props from best example for new_label\n",
    "                best_ex_dict = find_best_example_for_label(manager, attach_to=attach_to, label_substring = new_label)\n",
    "                if best_ex_dict is not None:\n",
    "                    ex = best_ex_dict['best_example']\n",
    "                else:\n",
    "                    ex = None\n",
    "                \n",
    "                props = {}\n",
    "                if ex is not None:\n",
    "                    props = ex.get(\"props\", {})\n",
    "                    if isinstance(props, str):\n",
    "                        try: props = json.loads(props)\n",
    "                        except Exception: props = {\"_raw_props\": props}\n",
    "                    props = dict(props or {})\n",
    "                    props.update({\n",
    "                        \"source\": \"suggested_node_from_dataset\",\n",
    "                        \"matched_label\": ex.get(\"label\",\"\"),\n",
    "                        \"matched_graph_id\": ex.get(\"gid\",\"\"),\n",
    "                        \"matched_vertex_id\": ex.get(\"id\",\"\"),\n",
    "                    })\n",
    "                    x = best_ex_dict['recommended']['x']\n",
    "                    y = best_ex_dict['recommended']['y']\n",
    "                    z = best_ex_dict['recommended']['z']\n",
    "                else:\n",
    "                    x = y = z = 0.0\n",
    "                    props = {\"label\": new_label, \"source\": \"suggested_node_no_example\"}\n",
    "                create_vertex(manager, working_graph_id, local_id=new_id, label=new_label,\n",
    "                              props=props, x=x, y=y, z=z)\n",
    "                create_edge_bidirectional(manager, working_graph_id, attach_to, new_id, label=\"suggested\",\n",
    "                                          props={\"source\": \"llm\"})\n",
    "            else:\n",
    "                no_action += 1\n",
    "\n",
    "        elif action.get(\"action\") == \"connect\":\n",
    "            a = str(action.get(\"a\") or \"\").strip()\n",
    "            b = str(action.get(\"b\") or \"\").strip()\n",
    "            if a and b and a != b:\n",
    "                applied = create_edge_bidirectional(manager, working_graph_id, a, b, label=\"suggested\",\n",
    "                                          props={\"source\": \"llm\"})\n",
    "                if not applied:\n",
    "                    no_action +=1\n",
    "        else:\n",
    "            return {\"snapshots\": snapshots, \"actions\": actions_log, \"reason\": action.get(\"reason\",\"Stopped.\")}\n",
    "\n",
    "        actions_log.append(action)\n",
    "        snapshots.append(snapshot_full_graph(manager, working_graph_id))\n",
    "\n",
    "        if no_action > patience:\n",
    "            print(\"Ran out of patience with no action. Stopping.\")\n",
    "            return {\"snapshots\": snapshots, \"actions\": actions_log, \"reason\": \"Action produced no change.\"}\n",
    "\n",
    "    return {\"snapshots\": snapshots, \"actions\": actions_log, \"reason\": f\"Reached max steps ({max_steps}).\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45668977",
   "metadata": {},
   "source": [
    "## Create a Kuzu DB Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb91a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this next line is useful for windows\n",
    "#db_path = \"C:/Users/sarwj/OneDrive - Cardiff University/Desktop/demo_kuzu\"         # Kùzu DB directory (will be created/used)\n",
    "#mgr = Kuzu.Manager(db_path)\n",
    "\n",
    "# Configuration: Paths\n",
    "db_path = \"./demo_kuzu\"  # Kùzu DB directory (will be created in project root)\n",
    "mgr = Kuzu.Manager(db_path)\n",
    "print(f\"✓ Kuzu database initialized at: {db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76151118",
   "metadata": {},
   "source": [
    "## Import the graphs and store in Kuzu (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b2e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: This next line works on windows\n",
    "#json_folder = \"C:/Users/sarwj/OneDrive - Cardiff University/Desktop/msd_json/sample_graphs\"        # folder with your *.json graphs\n",
    "\n",
    "\n",
    "# Configuration: Swiss dwelling dataset path\n",
    "json_folder = \"/Users/td3003/import_export/msd_json/sample\"  # Swiss dwelling dataset\n",
    "\n",
    "print(f\"Importing graphs from: {json_folder}\")\n",
    "_ = Kuzu.EmptyDatabase(mgr, recreateSchema=False)\n",
    "gids = import_folder_to_kuzu(json_folder, mgr, undirected=True)\n",
    "print(\"Imported\", len(gids), \"graphs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868a538e",
   "metadata": {},
   "source": [
    "## Expand the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a578b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a new working graph from a seed label that copies props from dataset\n",
    "result = graphrag_build_loop(mgr,\n",
    "                             working_graph_id = \"work_demo\",\n",
    "                             start_label = \"Entry\",\n",
    "                             description = \"4 bedroom apartment with home office and a nursery\",\n",
    "                             max_steps = 12,\n",
    "                             patience = 2,\n",
    "                             max_connections = 2)\n",
    "print(result[\"reason\"])    # why it stopped\n",
    "result[\"actions\"]           # actions chosen at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d647651e",
   "metadata": {},
   "source": [
    "## The Final Resulting Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b16bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "last_graph = result[\"snapshots\"][-1]  # TopologicPy Graph representation of the last graph\n",
    "Topology.Show(last_graph,\n",
    "              backgroundColor=\"white\",\n",
    "              vertexLabelKey=\"label\",\n",
    "              showVertexLabel=True,\n",
    "              vertexSize=10,\n",
    "              width=800,\n",
    "              height=800,\n",
    "              camera=[0,0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Topology.Show(last_graph,\n",
    "              backgroundColor=\"white\",\n",
    "              vertexLabelKey=\"roomtype\",\n",
    "              showVertexLabel=True,\n",
    "              vertexSize=10,\n",
    "              width=800,\n",
    "              height=800,\n",
    "              camera=[0,0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3518c42",
   "metadata": {},
   "source": [
    "## Show the sequence of suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9764ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result[\"snapshots\"])):\n",
    "    graph = Graph.Reshape(result[\"snapshots\"][i], silent=True)  # TopologicPy Graph (if available) or dict\n",
    "    vertices = Graph.Vertices(graph)\n",
    "    for v in vertices:\n",
    "        d = Topology.Dictionary(v)\n",
    "        print(Dictionary.Keys(d), Dictionary.Values(d))\n",
    "    Topology.Show(graph, backgroundColor=\"white\", vertexLabelKey=\"roomtype\", showVertexLabel=True, vertexSize=10, width=400, height=400, camera=[0,0,4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
